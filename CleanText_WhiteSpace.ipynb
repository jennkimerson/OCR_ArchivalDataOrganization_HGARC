{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CleanText_WhiteSpace.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jennkimerson/OCR_ArchivalDataOrganization_HGARC/blob/master/CleanText_WhiteSpace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_iWlq4Xjonej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text Cleaning, Tokenization, Text Manipulation, White Space Consideration"
      ]
    },
    {
      "metadata": {
        "id": "R3HXJz4LeSn7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple Python Text Cleaning\n",
        "- Split by white space\n",
        "- Remove puncuations\n",
        "- Convert all text to lower case"
      ]
    },
    {
      "metadata": {
        "id": "Tux_FDoWcst9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "filename = \"kafka.txt\"\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nFLMtLSrdbDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cce91035-fa6b-4f26-c2eb-3bb045fb0320"
      },
      "cell_type": "code",
      "source": [
        "# split by white space\n",
        "words = text.split()\n",
        "\n",
        "print(words[:100])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['One', 'morning,', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'He', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'His', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '\"What\\'s', 'happened', 'to', 'me?\"', 'he', 'thought.', 'It', \"wasn't\", 'a', 'dream.', 'His', 'room,', 'a', 'proper', 'human']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jyxeivnudds_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9c59f2e6-5dd8-46d8-81d8-6e14273a918b"
      },
      "cell_type": "code",
      "source": [
        "# remove puncuations\n",
        "import string\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "stripped = [w.translate(table) for w in words]\n",
        "\n",
        "print(stripped[:100])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['One', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'armourlike', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'Whats', 'happened', 'to', 'me', 'he', 'thought', 'It', 'wasnt', 'a', 'dream', 'His', 'room', 'a', 'proper', 'human']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o333TYN5derh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ab4e22fe-c3eb-42cd-9f7c-a4edae2a9af9"
      },
      "cell_type": "code",
      "source": [
        "# to lower case\n",
        "words = [word.lower() for word in words]\n",
        "\n",
        "print(words[:100])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['one', 'morning,', 'when', 'gregor', 'samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'he', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'the', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'his', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '\"what\\'s', 'happened', 'to', 'me?\"', 'he', 'thought.', 'it', \"wasn't\", 'a', 'dream.', 'his', 'room,', 'a', 'proper', 'human']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qf_12zM0eJjN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenization and Text Cleaning with NLTK (Natural Language Toolkit)\n",
        "\n",
        "Refrence / Creidt to: https://machinelearningmastery.com/clean-text-machine-learning-python/"
      ]
    },
    {
      "metadata": {
        "id": "mq_gtd5hd_q_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "02f4e3fb-cd2d-4cd0-b984-f17a9790a4d7"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U nltk\n",
        "import nltk"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.4)\n",
            "Requirement already satisfied, skipping upgrade: singledispatch in /usr/local/lib/python3.6/dist-packages (from nltk) (3.4.0.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zaHi11jZeBo9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "filename = \"kafka.txt\"\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VThpZqcPeh-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e989ecf7-4b29-4296-dd58-d9c3c856dc9a"
      },
      "cell_type": "code",
      "source": [
        "# split into sentences\n",
        "from nltk import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "print(sentences[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One morning, when Gregor Samsa woke from troubled dreams, he found\n",
            "himself transformed in his bed into a horrible vermin.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "i2xPwqJvfs1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2d1d2a64-bf77-48f9-8ec6-88b89747a97a"
      },
      "cell_type": "code",
      "source": [
        "# split into words\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "print(tokens[:100])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['One', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', 'He', 'lay', 'on', 'his', 'armour-like', 'back', ',', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', ',', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', '.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', '.', 'His', 'many', 'legs', ',', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', ',', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', '.', '``', 'What', \"'s\", 'happened', 'to']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sh9cwjc4gCSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4650c913-80b5-4d9b-e2c4-ecb7bb2cff11"
      },
      "cell_type": "code",
      "source": [
        "# remove puncuations\n",
        "words = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "print(words[:100])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['One', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'What', 'happened', 'to', 'me', 'he', 'thought', 'It', 'was', 'a', 'dream', 'His', 'room', 'a', 'proper', 'human', 'room']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IwFbsITAg_58",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dealing with White Spaces"
      ]
    },
    {
      "metadata": {
        "id": "ZQB2do3KkZdk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Sample program to test out counting leading white spaces and replacing it with a filler"
      ]
    },
    {
      "metadata": {
        "id": "5cBCN_XNgIsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "aede9139-5850-4bbe-da6d-a1524068e83c"
      },
      "cell_type": "code",
      "source": [
        "# count leading white spaces\n",
        "\n",
        "import itertools\n",
        "\n",
        "text1 = \" leading spaces\"\n",
        "text2 = \"  leading spaces\"\n",
        "text3 = \"   leading spaces\"\n",
        "\n",
        "count1 = str(sum( 1 for _ in itertools.takewhile(str.isspace, text1)))\n",
        "count2 = str(sum( 1 for _ in itertools.takewhile(str.isspace, text2)))\n",
        "count3 = str(sum( 1 for _ in itertools.takewhile(str.isspace, text3)))\n",
        "\n",
        "print(\"For text  1\")\n",
        "print(\"Expected: 1\")\n",
        "print(\"Counted:  \" + count1)\n",
        "print()\n",
        "\n",
        "print(\"For text  2\")\n",
        "print(\"Expected: 2\")\n",
        "print(\"Counted:  \" + count2)\n",
        "print()\n",
        "\n",
        "print(\"For text  3\")\n",
        "print(\"Expected: 3\")\n",
        "print(\"Counted:  \" + count3)\n",
        "print()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For text  1\n",
            "Expected: 1\n",
            "Counted:  1\n",
            "\n",
            "For text  2\n",
            "Expected: 2\n",
            "Counted:  2\n",
            "\n",
            "For text  3\n",
            "Expected: 3\n",
            "Counted:  3\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uqfCTuk1io86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22de44b0-fe64-41b1-e5e1-6998d0ba9c94"
      },
      "cell_type": "code",
      "source": [
        "# replaces white spaces with filler\n",
        "print(text1.replace(\" \", \"-\"))\n",
        "\n",
        "\n",
        "# replaces white spaces with unique filler markers\n",
        "\n",
        "count = str(sum( 1 for _ in itertools.takewhile(str.isspace, text)))\n",
        "if "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----leading-spaces\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oNhQ9bd_pBbW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Idea (left off on March 18th)\n",
        "Preserve white spaces using the counted spaces and \"just\" function."
      ]
    },
    {
      "metadata": {
        "id": "_4J1dsnKlCEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#.rjust(n) and .ljust(n)\n",
        "# return a padded version of the string they are called on, \n",
        "# with spaces inserted to justify the text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "br_aRGCYkqOr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Using real data"
      ]
    },
    {
      "metadata": {
        "id": "73MRJjsshLRz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "filename = \"cleantext.txt\"\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6Of06SUk-Es",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3d8a7f6e-23b3-4fa8-e734-59b7eaa3520d"
      },
      "cell_type": "code",
      "source": [
        "# split into sentences\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences[0])\n",
        "print(sentences[1])\n",
        "print(sentences[2])\n",
        "print(sentences[3])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Leading space is 1.\n",
            "Leading space is 2.\n",
            "Leading space is 3.\n",
            "Leading space is 4.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}