# -*- coding: utf-8 -*-
"""Mk4_Beta.Formfield.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QZxeSUqIMdXYfXDTeWD0nMFWYAyAupIy

You must install all of the following configurations:
pip install PyPDF2
sudo apt-get update
sudo apt install poppler-utils


pip install pdf2image

pip install pytesseract
sudo apt install tesseract-ocr
pip install opencv-python

pip install XlsxWriter
pip install pandas

To run on python virtual environment on your local computer, pleaes type in the following command to your shell:
source mypython/bin/activate
mypthon\Scripts\activate

To exit python virtual environment:
deactivate

# Mk. 4
Reads in text by binding individual characters with boxes in attempts to preserve white spaces.

User friendly version of Mk4 Beta Version.
Currently prints all the debug line for programmer's benefits; will be deleted when released to users to avoid confusion and for conciseness.

## I. Data Selection
Prompts the user to select pages they want to read in
"""

#@title ## Installation
#@markdown Run to install / import necessary python libraries to run this program (this may take some time).


#install PyPDF2
#!pip install PyPDF2
import PyPDF2
from PyPDF2 import PdfFileReader, PdfFileWriter
import os.path


#!sudo apt-get update
#!sudo apt install poppler-utils

#install pdf2image
#!pip install pdf2image
from pdf2image import convert_from_path



# import necessary python libraries for image enhancement
import numpy as np
import cv2
from PIL import Image


#install pytesseract for OCR
#!pip install pytesseract
#!sudo apt install tesseract-ocr

# import necessary python libraries for OCR
import pytesseract
from pytesseract import Output

try:
    from PIL import Image
except ImportError:
    import Image
    
import cv2

import numpy as np


# import necessary python library
import re as regex

#! pip install XlsxWriter
#! pip install pandas
import pandas as pd

#@title ## File Selection
#@markdown Please select a file to be read in

# USER INPUT: PDF FILE
#takes in a file from the user and imports the image file
#from google.colab import files
#print("Please select a PDF file.")
#uploaded = files.upload()

pdfFileObj = open('sample.pdf', 'rb')

#@title ## File Path Configuration
#@markdown Please enter the name of the document

# configures file path

file_path = ''

while True:
  input_path = input("Document name: ")
  if os.path.exists(input_path + '.pdf'):
    file_path = input_path + '.pdf'
    break
  print("File not found.")

#@title ## Page Selection
#@markdown Please select the pages that is to be read in

# PAGE SELECTION

input_file = PdfFileReader(open(file_path,'rb'))
page_count = input_file.getNumPages()

print("This document contaions " + str(page_count) + " page(s). " "Please select pages to be read in.")
print("If you want a single page to be read in, type in the same page number for both start and last page.")

while True:
  input_start = input("Start page: ")
  if input_start.isdigit() and int(input_start) > 0 and int(input_start) < page_count:
    break
  else:
    print("You must select a page number greater than 1 and less than " +  str(page_count) + ".")      

while True:
  input_last = input("Last page: ")
  if input_last.isdigit() and int(input_last) <= page_count:
    if int(input_last) >= int(input_start):
      break
    else:
      print("Your last page number should be larger than start page number, which is " + str(input_start) + ".")
  else:
    print("You must select a page number less than " + str(page_count) + " page(s).")

print("All set!")

"""## II. File Conversion
Read in PDF to images (TIF)
"""

#@title ## Page Conversion
#@markdown Run to convert each .pdf pages into a .tif formatted images

# PAGE CONVERSION
# Converts each .pdf pages into a .tif format images

pdf_writer = PdfFileWriter()

for page_num in range(int(input_start) - 1, int(input_last)):
  pdf_writer.addPage(input_file.getPage(page_num))
  
selection = 'selection.pdf'
 
with open(selection, 'wb') as out:
  pdf_writer.write(out)

pages = convert_from_path(selection, 400) #convert_from_path(file_name, dpi) returns an array of images, one for each page

p_range = range(len(pages))

for i in p_range:
  pages[i].save('input' + str(i) + '.tif', 'TIFF')

"""## III. Enhance Image
Reduce the background noise in images for accurate scanning
"""

#@title ## Read in the file
#@markdown Run to read in each images.

#@markdown At this stage, images are being enhanced for better machine reading.

# READ

for i in p_range:
  img = cv2.imread('input' + str(i) + '.tif', cv2.IMREAD_GRAYSCALE)
  
  """increase contrast"""
  """would like to scale on a non-linear level but have yet to understand how to do such"""
  pxmin = np.min(img)
  pxmax = np.max(img)
  imgContrast = np.round((img / 255)) * 255
  # (debug line) print(pxmin, pxmax)
  
  # (debug line) print(img.shape)
  
  """noise removal via closing technique"""
  kernel = np.ones((2, 2), np.uint8)
  imgCleaned = cv2.erode(imgContrast, kernel, iterations = 2)
  imgCleaned = cv2.dilate(imgCleaned, kernel, iterations = 3)
  # cv2.morphologyEx(imgContrast, cv2.MORPH_CLOSE, kernel)
  
  """write"""
  cv2.imwrite('cleaned' + str(i) + '.tif', imgCleaned)

  """save"""
  img = Image.open('cleaned' + str(i) + '.tif')
  rgb_img = img.convert('RGB')
  rgb_img.save('cleaned' + str(i) + '.tif')
  
  # """increase line width"""
  # kern = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))
  # imgWord = cv2.erode(imgCleaned, kern, iterations = 1) #- cv2.dilate(imgContrast, kern, iterations = 1)
  
  # """write"""
  # cv2.imwrite('words' + str(i) + '.tif', imgWord)

  # """save"""
  # img = Image.open('words' + str(i) + '.tif')
  # rgb_img = img.convert('RGB')
  # rgb_img.save('words' + str(i) + '.tif')
  
  # cv2.imwrite('cont' + str(i) + '.tif', imgContrast)
  
  # img = Image.open('cont' + str(i) + '.tif')
  # rgb_img = img.convert('RGB')
  # rgb_img.save('cont' + str(i) + '.tif')

"""##IV. Binding boxes with Enclosed Characters
Finds all text characters in the image and returns binidng boxes with enclosed characters
"""

#@title ## Read in the text
#@markdown Run to read in the text on each pages.

#@markdown At this stage, the program draws enclosed boxes around each text found on pages during OCR (Optical Character Recognition) process. 

# DRAW ENCLOSED BOXES AROUND EACH TEXT FOUND DURING OCR

for i in p_range:
  img = Image.open('cleaned' + str(i) + '.tif')
  # cover = Image.open('words' + str(i) + '.tif')
  # debg = Image.open('cont' + str(i) + '.tif')
  
  """draw boxes around each of the found characters"""
  
  nparray = np.array(img)
  # oparray = np.array(cover)
  
  frame = nparray

  H, W, _ = nparray.shape

  """char with bounding boxes"""
  boxes = pytesseract.image_to_boxes(img)
  # cover_boxes = pytesseract.image_to_boxes(cover)

  """draw the bounding boxes on the image"""
  for b in boxes.splitlines():
      b = b.split(' ')
      draw = cv2.rectangle(frame, (int(b[1]), H - int(b[2])), (int(b[3]), H - int(b[4])), (0, 255, 0), 2) #currently outputs wrong color scheme
      
  # for cb in cover_boxes.splitlines():
  #    cb = cb.split(' ')
  #    # print(cb[1])
  #    # print(int(cb[1]))
  #    draw = cv2.rectangle(frame, (int(cb[1]), H - int(cb[2])), (int(cb[3]), H - int(cb[4])), (100, 100, 255), 2)

  """fix color error"""
  RGB_img = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)
  
  """show result"""
  from google.colab.patches import cv2_imshow 
  #%matplotlib
  cv2_imshow(RGB_img)

"""##V. Coordinates to Lines
Get coordinates of all boxes in order to find the minimum x coordniate value. This is where we will start counting white spaces.
"""

#@title ## Define image Size
#@markdown Run to find define of the segmented image in width and hieght

#find size of the segmented image in width and hieght

width, height = img.size
# (debug line) print (width, height)

"""Assign meaningful names to box indices"""
x = 1
y = 2
w = 3
h = 4

#@title ## Configuration - Part 1
#@markdown Run to configure structures of the pages.

#@markdown At this stage, we remove noises and take in the coordinates of each text enclosed by boxes.
#@markdown Then, we parse them through to categorize them to group them together:

#@markdown - Group texts by sentences
#@markdown - Preserve white spaces and indentations

"""Creation of sub-processes"""

def trimX(boxList):
  """
  Set the leftmost occupied x-coordinate to 0
  """
  
  # EXTRACT ALL X-COORDINATES FROM BOXES
  xcoords = [int(box[x]) for box in boxList]
  # (debug line) print(xcoords)

  # FIND MINIMUM X-COORDINATE
  x_min = min(xcoords)
  # (debug line) print ("min x coordinate vlaue : ", x_min)

  # SHIFT ALL VALUES DOWN APPROPRIATELY - MUTATES INPUT
  for box in boxList:
    box[x] = int(box[x]) - x_min
    box[y] = int(box[y])
    box[w] = int(box[w]) - x_min
    box[h] = int(box[h])

  """
  # FIND THE SPAN OF THE DOCUMENT (This section isn't necessary)
  x_max = max(xcoords)
  # (debug line) print ("max x coordinate vlaue : ", x_max)

  span = x_max - x_min  
  # (debug line) print ("Span of text in the document: ", span)
  """
  
  return boxList

def getStats(boxList):
  """
  Determine average font size and standard deviation
  """
  
  # GATHERS ALL X AND Y LENGTHS
  f_x = []
  f_y = []
  for box in boxList:
    f_x.append(box[w] - box[x])
    f_y.append(box[h] - box[y])    
  # (debug line) print(f_x)
  # (debug line) print(f_y) 
  
  # CALCULATES STATISTICAL VALUES WITH NUMPY
  f__x = np.mean(f_x)
  f__y = np.mean(f_y)
  sigma_x = np.std(f_x)
  sigma_y = np.std(f_y)
  # (debug line) print("average font size, x direction: ", f__x)
  # (debug line) 
  print("average font size, y direction: ", f__y)
  # (debug line) print("standard deviation, x direction: ", sigma_x)
  # (debug line) 
  print("standard deviation, y direction: ", sigma_y)
  
  return [f__x, f__y, sigma_x, sigma_y]

def removeNoise(boxList):
  """
  Eliminates non-text noise by scanning for extremely large / small boxes
  Need to have getStats beforehand
  """
  
  # SETS LOWER AND UPPER BOUNDS FOR BOX DIMENSIONS
  x_l = int(f__x / 3)
  x_u = int(f__x * 3)
  
  # CREATES A NEW LIST THAT EXCLUDES ALL NOISE
  boxFilt = []
  for box in boxList:
    if box[w] - box[x] > x_l and box[w] - box[x] < x_u:
      boxFilt.append(box)
  
  return boxFilt  


def isUpperChar(char):
  """ 
  listed characters hinder deciding upper bounds for boxes
  """
  return char in ["\"", "\'", "‘", "’", "“", "”", "%"]
  
  
def isLowerChar(char):
  """ 
  listed characters hinder deciding lower bounds for boxes
  """
  return char in ["g", "j", "p", "y", ")", "(", "&"]
  
  
def toLines(boxList):
  """
  Identify and separate boxes with respect to y-clusters
  Need to have getStats beforehand, as well as set a dev_y
  """
  
  # IDENTIFY AND FORM Y-CLUSTERS
  lines_y = []
  boxLines = []  
  for box in boxList:
    if box[h] - box[y] > 0:
      y_val = box[y]
      
      # Special measures are taken for characters that don't follow the base line
      if isUpperChar(box[0]):
        y_val -= int(round(f__y))
      if isLowerChar(box[0]):
        y_val += int(round(f__y / 2))

      wingspan = range(y_val - dev_y, y_val + dev_y + 1)
      upperspan = range(y_val - dev_y + int(round(f__y)), y_val + dev_y + 1 + int(round(f__y)))
      lowerspan = range(y_val - dev_y - int(round(f__y) / 2), y_val + dev_y + 1 - int(round(f__y) / 2))

      if set(wingspan).isdisjoint(set(lines_y)):
        # (debug line) print(wingspan)
        if isUpperChar(box[0]) and not set(upperspan).isdisjoint(set(lines_y)):
          # This takes care of the OCR drawing boxes around the quotation marks oddly
          wingspan = upperspan
        elif isLowerChar(box[0]) and not set(lowerspan).isdisjoint(set(lines_y)):
          # This takes care of the OCR drawing boxes around underline characters oddly
          wingspan = lowerspan
        else:
          boxLines.append([])
          lines_y.append(y_val)

      lineDex = lines_y.index(list(set(lines_y) & set(wingspan))[0])
      boxLines[lineDex].append(box)
  # (debug line) print(lines_y)
  # (debug line) print("number of lines: ", len(lines_y))
  # (debug line) print(boxLines)
  # (debug line) [print(line) for line in boxLines]
  
  
  def ykey(line):
    """
    Sort y clusters
    """
    return line[0][y]
  boxLines.sort(key = ykey, reverse = True)
  
  # SORT LINES (in case scan order is wrong)
  def xkey(box):
    return box[x]
  for lines in boxLines:
    lines.sort(key = xkey)
  
  # (debug line) [print(line) for line in boxLines]
  
  return boxLines

"""STILL NEED TO IMPLEMENT AND REFINE"""
def toText(boxlines):
  return ""

#@title ## Configuration - Part 2
#@markdown Run to configure structures of the pages.

#@markdown At this stage, we define specifics of the structure to account for errors, such as variation in text sizes.
#@markdown Then we assemble strings of characters while editing the rawline to add intraword and interword spaces.

#find all characters and their coordinates in the image
from pytesseract import pytesseract as pt

document = ""
parseMat = []

for i in p_range:
  # (debug line) print(i)
  img = Image.open('cleaned' + str(i) + '.tif')
  coord = pt.image_to_boxes(img)
  # (debug line) print(coord)
  
  
  """Break string"""
  coordListPrep = sentences = coord.splitlines()
  #coordList = coord[0:len(coord)-1].split("\n")
  # (debug line) print(coordListPrep)

  coordList = []
  for i in range(0, len(coordListPrep)):
    new = coordListPrep[i].split(" ")
    coordList.append(new)
    
  # (debug line) print(coordList)
  
  """Zero the leftmost x-coordinate"""
  trimList = trimX(coordList)

  # (debug line) print(trimList)  
  
  """Obtain stats of the page"""
  [f__x, f__y, sigma_x, sigma_y] = getStats([box for box in trimList if box[0].isalnum()])
  
  """Filter out the noise"""
  filtList = removeNoise(trimList)
  
  """Derive extra parameters from stats"""
  # DEVIATIONS
  # dev_x = round(k * sigma_x)
  dev_y = int(4.5 * round(sigma_y))
  
  # TOLERANCE
  k = 1.2 #this should be adjusted
  tau = f__x + sigma_x * k
  
  """Cluster boxes by y-coordinate"""
  boxLines = toLines(filtList)
  
  """Assemble raw strings and also edit rawline to add intraword and interwrod spaces"""
  rawlines = []
  for line in boxLines:
    rawline = "" + int((line[0][x]) / tau) * " "

    for i in range(len(line)):
      box = line[i]
      rawline += box[0]

      if (i+1) == len(line):
        break

      nextbox = line[i + 1]

      #adjust sigma_x coefficient as needed
      gap = nextbox[x] - box[w]

      if gap >= tau:
        space = int(gap / tau)
        rawline += space * " "
    
    print(rawline)
    
    rawlines.append(rawline + "\n")
    parseMat.append(rawline + "\n")

  # print(rawlines)
  
  text = " ".join(rawlines)

  #print(text)
  
  document += text + "\n"

# document

#@title ## Listing Removals
#@markdown Run to remove listings

#@markdown Listings must be removed as we only want to preserve the content when pasting it onto the excel file in the last stage.

#@markdown PROGRAMMER TODO: Make removeListings optional and possibly streamline this process


def removeListings(line):
  """
  Remove listings to extract structure
  """
  
  charArray = list(line)
  leftBound = -1
  rightBound = -1
  alphnumCount = 0
  
  for i in range(len(charArray) - 2):
    if charArray[i].isalnum():
      alphnumCount += 1
      if alphnumCount > 9: 
        # probably not going to have a listing after that many characters
        break
    if charArray[i + 1] == ' ' and str(charArray[i + 2]).isspace() \
    and (charArray[i] == '.' or charArray[i] == ')' or charArray[i] == ','):
      sentinel = False
      bottomOut = False
      for j in range(i - 1, i - 5, -1):
        if j == -1:
          bottomOut = True
          break
        if charArray[j].isalnum():
          sentinel = True
        if not charArray[j].isalnum():
          if sentinel and charArray[j] == ' ':
            if j == 0 or (j != 0 and charArray[j - 1] == ' '): 
              if isListing(str(line[j + 1:i])):
                leftBound = j
          break
      if bottomOut and sentinel:
        leftBound = 0
      if leftBound != -1:
        rightBound = i
        break        
        
  if leftBound != -1 and rightBound != -1:
    return str(line[:leftBound]) + " " * (rightBound - leftBound + 1) + str(line[rightBound + 1:]) 
  else:
    return line
  
def isListing(small):
  if regex.search(r'\b([iIl])?([xXvViIl])+\b', small) \
  or regex.search(r'\b' + regex.escape(small[0]) + r'+\b', small) \
  or regex.search(r'\b([\dl])+\b', small):
    return True
  else:
    return False
  
"""Note: need to make removeListings optional and possibly streamline this process"""
final = ""

for lines in parseMat:
  # print(removeListings(lines))
  final += (removeListings(lines))

print(final)

"""## VI. Structure Selection & Data Categorization
Prompts the user for structure (formatting and organization of data)
"""

#@title ## Sentence Configuration

#@markdown At this stage, the program seperates text into an array of strings by line

n = 0
c = 1

"""seperate text into an array of strings by line"""
sentences = final.splitlines()
print(sentences)

#@title ## Line Configuration
#@markdown Run to configure line structures.

#@markdown At this stage, the program partitions lines given a large block of white space in between.

def partitionLines(charLines):
  """
  Partitions lines given a large block of white space in between
  """
  
  partedLines = []
  
  for line in charLines:
    charFront = False
    bigGap = False
    comboMeter = 0
    for charInd in range(len(line)):
      char = line[charInd]
      if char != " ":
        charFront = True
        comboMeter = 0
      if char == " " and charFront == True:
        comboMeter += 1
      if comboMeter > 4: # THIS CONDITION WILL VARY PER AID
        bigGap = True
        partedLines.append(line[:charInd])
        partedLines.append(" " * charInd + line[charInd:])
        break
    if not bigGap:
      partedLines.append(line)
  
  return partedLines

# CREATE SPACE COUNTING FUNCTION
def getStartSpaces(line):
    startSpaces = 0
    for char in line:
      if char == " ":
        startSpaces += 1
      else:
        return startSpaces
    return 1000 # case in which there's nothing in the line

def toCategories(charLines):
  """
  Sorts lines based on their respective categories, 
  determined from starting whitespace
  """  
  
  # IDENTIFY AND FORM HORIZONTAL CLUSTERS
  space_groups = []
  boxCateg = []
  for line in charLines:
    s_val = getStartSpaces(line)

    wingspan = range(s_val - 2, s_val + 2)

    if set(wingspan).isdisjoint(set(space_groups)):
      # (debug line) print(wingspan)
      boxCateg.append([s_val, []])
      space_groups.append(s_val)

    lineDex = space_groups.index(list(set(space_groups) & set(wingspan))[0])
    boxCateg[lineDex][c].append(line)
      
  # (debug line) print(space_groups)
  # (debug line) print("number of categories: ", len(space_groups))
  # (debug line) print(boxCateg)
  # (debug line) print([category for category in boxCateg])
  
  return boxCateg

sepLines = partitionLines(sentences)

catgList = toCategories(sepLines)

catgList

#@title ## Organization - Part 1
#@markdown Run to remove unnecessary spaces and select the correct categories for each row to organize them.

def removeStartSpaces(line):
    """
    remove all start spaces
    """
    for charInd in range(len(line)):
      if line[charInd] != " ":
        return line[charInd:]

def askUser(catgList):
  """
  display sample set of each category and prompt the user to select and categorize
  """
  
  for categInd in range(len(catgList)):
    """
    display examples of each categories to the usera
    """
    print("=== CATEGORY " + str(categInd + 1) + " ===")
    category = catgList[categInd][c]
    for lineInd in range(len(category)):
      if lineInd < 3:
        print(removeStartSpaces(category[lineInd]))
        
  print("Take a look at the sample and determine the level / hierarchy of the categories.")
  print("Start by labeling the largest / first categorization as 1 and go down.")
  print("If you made a mistake naming the category, type 'c' to go back to previous.")
  print("If you want to ignore the category, type 'd'.")
  
  while True:
    
    orderTable = []
    
    while True:
      read = input("Level of each category: ")
      if len(read.split(", ")) == len(catgList):
        break
      else:
        print("Quantity of levels does not match inputted levels!")
        
    orderList = read.split(", ")
    improper = False
    
    for position in orderList:
      if position.isdigit() and int(position) > 0 and int(position) <= len(catgList):
        orderTable.append(int(position))
      elif position == 'd':
        orderTable.append(0)
      else:
        print("You must select a level between 1 and " +  str(len(catgList)) + " or input 'd' to ignore the category.")
        improper = True
        break
        
    if improper:
      continue
    else:
      break
    
  print("All set!")
    
  return orderTable
    
orderTable = askUser(catgList)

orderTable

#@title ## Organization - Part 2
#@markdown Run to modify layers.

def makeOrder(orderTable, spaceTable, charLines):
  orderList = []
  
  for line in charLines:
    s_val = getStartSpaces(line)
    wingspan = range(s_val - 2, s_val + 2)
    
    dex = spaceTable.index(max(list(set(spaceTable) & set(wingspan))))
    if orderTable[dex] != 0:
      orderList.append([orderTable[dex], removeStartSpaces(line)])
  
  return orderList

orderList = makeOrder(orderTable, [catg[n] for catg in catgList], sepLines)

"""THIS SECTION IS STILL IN DEVELOPMENT - CAN AND WILL CRASH"""
def removePairs(orderList):
  cleanList = orderList.copy()
  peakOrd = max([pair[n] for pair in orderList])
  orderLines = [[] for _ in range(peakOrd)]
  
  for i in range(len(orderList)):
    orderLines[orderList[i][n] - 1].append([i, orderList[i][c]])
  
  snipeInd = []
  modify = "Y"
  
  while modify is "Y":
    print("Which layer would you like to modify?")
    level = -1
    while True:
      level = input("Layer to modify: ")
      if not level.isnumeric():
        print("Level must be a number. Please retry.")
        continue
      level = int(level) - 1
      if level not in range(0, peakOrd):
        print("Layer must be between 1 and " + str(peakOrd) + ".")
        continue
      break
    print("Accessing layer " + str(level + 1) + ".")
    print("=== LAYER " + str(level + 1) + " ===")
    for i in range(len(orderLines[level])):
      print("Item " + str(i + 1) + ": " + orderLines[level][i][c])
    print("Which items would you like to remove?")
    items = []
    while True:
      print("List the items that you want to remove, separated by a comma and space.")
      items = input("Items to remove: ").split(", ")
      if not items:
        print("List is empty. Please retry.")
        continue
      for item in items:
        if not item.isnumeric():
          print("Not all of the values are numeric. Please retry.")
          continue
        if not int(item) - 1 in range(len(orderLines[level])):
          print("Item number is out of bounds. Please retry.")
          continue
      items = [int(item) - 1 for item in items]
      dexes = [orderLines[level][item][n] for item in items]
      if not set(dexes).isdisjoint(set(snipeInd)):
        print("Some items listed have already been specified for removal. Please retry.")
        continue
      snipeInd = snipeInd + dexes
      break
    print("Would you like to remove more items? (Y/N)")
    while True:
      modify = input()
      if not (modify is "Y" or modify is "N"):
        print("Please retry. (Input should be either \"Y\" or \"N\")")
        continue
      break
    
  print(snipeInd)
  for dex in sorted(snipeInd, reverse = True):
    del cleanList[dex]
    
  return cleanList
    
orderList = removePairs(orderList) # need to change later

"""## VII. Tree Reorientation"""

#@title ## Create Node
#@markdown At this stage, the program creates basic tree data structure for organization and parsing.

class Node:
  """
  The individual terms in the psuedo-tree. Two pointers, [parent] and [akid]
  """
  
  def __init__(self, dat = None, par = None, kid = None):
    self.data = dat
    self.parent = par
    self.akid = kid
    
  def __str__(self):
    if self.parent:  
      return str(self.parent) + "~~~" + str(self.data)
    else:
      return str(self.data)
    
class Tree:
  """
  Climate change is a hoax created by the Chinese
  """
  
  def __init__(self, roo = Node()):
    self.root = roo
    
  def __str__(self):
    return str(self.root)

# BELOW IS EXPERIMENTATION
  
# oak = Tree(Node('Pog'))
# alpha = Node('Champ')
# alpha.parent = oak
# omega = Node('MonkaS')
# omega.parent = alpha
# birch = Tree(Node('Point'))
# birch.root.parent = Tree(Node('Check'))
# print(alpha)
# print(omega)
# print(oak.root)
# str(birch)

#@title ## Create Tree
#@markdown At this stage, the program continues to create basic tree data structure.

leaves = []

def makeTree(orderList, entry):
  order = 0
  content = 1
  
  if not entry:
    trunk = Tree(Node("Yggdrasil"))
    level = 0
  else:
    trunk = Tree(Node(entry[content]))
    level = entry[order]
    
  prev = 0
  pres = 0
  branch = None
  nextCatg = False
  
  for lineNum in range(len(orderList)):
    if nextCatg and orderList[lineNum][order] == level + 1:
      branch = makeTree(orderList[prev:lineNum], orderList[pres])
      branch.root.parent = trunk.root
      trunk.root.akid = branch
      if not branch.root.akid:
        leaves.append(branch.root)
      prev = lineNum
      pres = lineNum
    elif orderList[lineNum][order] == level + 1:
      nextCatg = True
      pres = lineNum
  
  if nextCatg:
    branch = makeTree(orderList[prev:len(orderList)], orderList[pres])
    branch.root.parent = trunk.root
    trunk.root.akid = branch
    if not branch.root.akid:
      leaves.append(branch.root)
  
  return trunk

makeTree(orderList, None)

for leaf in leaves:
  print(leaf)

"""## VIII. Reassemble Data
Create a CSV or Excel file with the processed data
"""

#@title ## Create Data Frame
#@markdown Formats it into correct data frame

shatterShot = [[] for leaf in leaves]
for shard in range(len(shatterShot)):
  shatterShot[shard] = str(leaves[shard]).split("~~~")[1:]
shatterShot

df = pd.DataFrame(shatterShot)
#df= pd.DataFrame(split)
#df = df.transpose()

print(df)

#@title ## Export to Excel
#@markdown Run the code to export

df.to_excel("output.xlsx")
